{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction to Data Science\n",
      "\n",
      "Welcome to [Zipfian Academy's](http://zipfianacademy.com) Introduction to Data Science exercise.  This exercise is an overview of the data science process through an end-to-end analysis of SF health inspection data.\n",
      "\n",
      "### Getting Help\n",
      "\n",
      "As always, feel free to email us about anything at all (questions, issues, concerns, feedback) at <a href=\"mailto:class@zipfianacademy.com\">class@zipfianacademy.com</a>.  We would love to hear how you liked the exercise, whether the content was technical enough (or too technical), or any other topics you wish were covered.\n",
      "\n",
      "### Next Steps\n",
      "\n",
      "We hope you have fun with this exercise!  If you want to learn more or dive deeper into any of these subjects, we are always happy to discuss (and can talk for days about these subjects). And if you just can't get enough of this stuff (and want a completely immersive environment), you can [apply](http://zipfiancollective.wufoo.com/forms/m7x3z9/) for our intensive data science bootcamp starting September 16th.\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                         \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Learning Python\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "This assignment assumes a basic familiarity with Python and is intended to teach you how to leverage it for data science.  If you do not feel comfortable enough with Python (and programming in general) I recommend these (freely available) resources:\n",
      "\n",
      "* [Think Python](http://www.greenteapress.com/thinkpython/thinkpython.pdf)\n",
      "* [MIT Open Courseware: A Gentle Introduction to Programming Using Python](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-189-a-gentle-introduction-to-programming-using-python-january-iap-2008/index.htm)\n",
      "* [Learn Python the Hard Way](http://learnpythonthehardway.org/book/)\n",
      "* [Python Koans](https://github.com/gregmalcolm/python_koans/wiki)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Setup and Environment\n",
      "\n",
      "This exercise is written in an [IPython](http://ipython.org/) [notebook](http://ipython.org/notebook.html) and uses many of wonderful libraries from the scientific Python [community](http://strata.oreilly.com/2013/03/python-data-tools-just-keep-getting-better.html).  While you do not need IPython locally to complete the exercise (there are PDF and .ipynb versions of these instructions), I recommend setting it up on your computer if you plan to continue learning and playing with data.  IPython [notebooks](http://ipython.org/ipython-doc/stable/interactive/htmlnotebook.html) not only provide an interface to interactively run (and debug) code in a web browser, but also to document your file as you go along.  Below are the steps to setup a scientific Python environment on your computer to complete this (and all future class') assignment.  If you have tips or suggestions to make this process easier, please reach out via email or [tweet](http://twitter.com/zipfianacademy) at us!\n",
      "\n",
      "Begin by cloning this [repository](https://github.com/Jay-Oh-eN/data-science-curriculum): `git clone http://github.com/Jay-Oh-eN/data-science-curriculum.git`\n",
      "\n",
      "### Version control and Environment Isolation\n",
      "* [Git](http://git-scm.com/): Distributed Version Control to keep track of changes and updates to files/data.\n",
      "* [virualenv](http://www.virtualenv.org/en/latest/): Python environment isolation to help manage dependencies with packages and versions.\n",
      "* [pythonbrew](https://github.com/utahta/pythonbrew): Manage and install multiple versions of Python.  Can be handy if you want to experiment with Python 3.x.\n",
      "\n",
      "### Scientific Python packages\n",
      "     \n",
      "* [Enthought Python Distribution](https://www.enthought.com/products/epd/free/): A freely available packaged environment for scientific Python.\n",
      "* [Scipy Superpack](http://fonnesbeck.github.io/ScipySuperpack/): Only for Mac OSX, but a one line shell script that installs all the fundamental scientific computing packages.\n",
      "* [pandas](http://pandas.pydata.org/): Data analysis and statistical library providing functionality in Python similar to [R](http://www.r-project.org/).\n",
      "\n",
      "<em>if you are on OSX, you may need to install [Xcode](http://developer.apple.com/library/ios/#documentation/DeveloperTools/Conceptual/WhatsNewXcode/Articles/xcode_4_3.html) (with command line utilities) or install [gcc](https://medium.com/kr-projects/6e54e8c50dc8) directly</em>\n",
      "   \n",
      "__[Tutorial](https://sites.google.com/site/pythonbootcamp/preparation/software) walking you through the installation of these tools, with [tests](https://sites.google.com/site/pythonbootcamp/preparation/testing-that-it-all-works) to make sure it all works.__"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise: Happy Healthy Hungry -- San Francisco\n",
      "\n",
      "Now that your environment is all setup up... the fun begins!  In this exercise we will walk through the data science [process](http://zipfianacademy.com/data/data-science-process.png).  We will be analyzing the inspections of San Francisco restaurants using publicly available [data](http://www.sfdph.org/dph/EH/Food/score/default.asp) from the Department of Public health.  We will learn to explore this data to map the cleanliness of the city, and get a better perspective on the relative meaning of these scores by looking at statistics of the data. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import pylab to provide scientific Python libraries (NumPy, SciPy, Matplotlib)\n",
      "%pylab --no-import-all\n",
      "\n",
      "# import the Image display module\n",
      "from IPython.display import Image\n",
      "\n",
      "# inline allows us to embed matplotlib figures directly into the IPython notebook\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: module://IPython.kernel.zmq.pylab.backend_inline\n",
        "Populating the interactive namespace from numpy and matplotlib\n",
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url='http://zipfianacademy.com/data/data-science-workflow/animate.gif', width=700)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://zipfianacademy.com/data/data-science-workflow/animate.gif\" width=\"700\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "<IPython.core.display.Image at 0x110ac16d0>"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## ___Let us explore our data___\n",
      "\n",
      "The ___Explore___ stage of the analysis is where we will most likely spend most of our [time](http://strataconf.com/stratany2012/public/schedule/detail/27495).  Now comes the fun part (in my opinion)!  At this stage we will use a variety of tools (the documentation of each linked to inline) to figure out where and how to obtain data, what it looks like once we have it, and how to use it to help us answer what questions we may have."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Acquire\n",
      "\n",
      "Luckily, San Francisco has much of its public government data freely [accessible](https://data.sfgov.org/) online.   There are also great [initiatives](http://www.yelp.com/healthscores) by SF [companies](http://officialblog.yelp.com/2013/01/introducing-lives.html) collaborating with [non-profits](http://codeforamerica.org/) and [government](http://sfgov.org/) to develop open data [standards](http://foodinspectiondata.us/).  Such standardization allows for much more transparency, leading ultimately to a more engaged citizenry.\n",
      "\n",
      "__The relevant [data](http://www.sfdph.org/dph/EH/Food/score/default.asp) has been downloaded for your convenience and can be found in the [repo](https://github.com/Jay-Oh-eN/data-science-curriculum).__"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Examine\n",
      "\n",
      "_If you are working with this IPython notebook, download the data files into the same directory which you ran the_ `ipython notebook`  _command_\n",
      "\n",
      "Now that we have found the relevant data we can begin to peer inside to understand what we are working with.  I recommend starting with an iterative approach, using the quickest/easiest tools first and slowly build to more complicated analyes.  UNIX provides us with many powerful tools and can carry us quite far by itself. In our case the dataset came with [documentation](https://s3.amazonaws.com/piazza-resources/hgtp0qhpaps1d5/hhfjlqv3gii2l8/File_Specifications.pdf?AWSAccessKeyId=AKIAJKOQYKAYOBKKVTKQ&Expires=1370258028&Signature=ZsHGKBMNwbdv9Ptio3b6GYrhB08%3D) of its contents, but it still is essential to look at the raw data and compare it to the docs."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 1.1: Display the first 5 lines of each of the data files (CSV files in SFBusinesses directory).\n",
      "\n",
      "#### Extra Credit: \n",
      "* Display the last 5 lines of each file\n",
      "* Format the output nicely into columns\n",
      "\n",
      "*Relevant resources:*\n",
      "  \n",
      "* [IPython tutorial](http://ipython.org/ipython-doc/rel-0.13.1/interactive/tutorial.html)\n",
      "* [IPthon: System Shell Access](http://ipython.org/ipython-doc/rel-0.13.1/interactive/reference.html#system-shell-access)\n",
      "* [head (UNIX)](http://en.wikipedia.org/wiki/Head_(Unix))\n",
      "* [UNIX pipes](http://en.wikipedia.org/wiki/Pipeline_(Unix))\n",
      "* [column (UNIX)](http://linux.about.com/library/cmd/blcmdl1_column.htm)\n",
      "* [tail (UNIX)](http://en.wikipedia.org/wiki/Tail_(Unix))"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___There are two different data directories, each of which has similar files.  Let's try to figure out the difference between the two, since the documentation on the data does not mention anything.___ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 1.2: Compare the files in SFBusinesses with SFFoodProgram_Complete_Data. For the corresponding files:\n",
      "* Display the first 5 lines of each file.\n",
      "* Compare the column names, column contents, and number of columns.\n",
      "* Compare the number of lines (records), word counts, and file size.\n",
      "\n",
      "#### Extra Credit: \n",
      "* Use [AWK](http://en.wikipedia.org/wiki/AWK) and Python to automate this for all the files in the directory (e.g. pass in two directories and spit out the relevant metrics)\n",
      "* Use IPython cell magics to run an entire shell as a bash script/process\n",
      "\n",
      "*Relevant resources:*\n",
      "  \n",
      "* [wc (UNIX)](http://en.wikipedia.org/wiki/Wc_(Unix))\n",
      "* [grep (UNIX)](https://en.wikipedia.org/wiki/Grep)\n",
      "* [IPython cell magics](http://nbviewer.ipython.org/url/github.com/ipython/ipython/raw/master/examples/notebooks/Cell%20Magics.ipynb)\n",
      "* [AWK](http://en.wikipedia.org/wiki/AWK)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Prepare\n",
      "\n",
      "This is typically what people refer to as data 'munging' (or 'wrangling') and often is the most tedious process when working with messy data. Due to increasing awareness of the importance of data quality, the city of SF has been making great strides in more open and [accessible](http://www.datasf.org/) data. If you (the city of SF) know the [format](http://www.yelp.com/healthscores) you will need going into the data collection process (inspecting restaurants) you can hopefully avoid a lot of pain later in the analysis process. \n",
      "\n",
      "The preparation process of our analysis is not as long and cumbersome as it typically might be due to the high quality of the raw data.  Because of this, I will spare you much of the tedium of this step so we can focus on the more interesting aspects of the analysis.  If you want to see (and experience) the pain (all you masochists out there), we will get much deeper into data acquisition and scrubbing techniques in our data wrangling post of this series."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Transform\n",
      "\n",
      "Now that we know the structure of our data, we can start to begin examining it statistically to get a macrosopic look at its distribution.  This part of our tutorial will use much of the powerful built in functionality of [NumPy](http://www.numpy.org/), [SciPy](http://www.scipy.org/), [matplotlib](http://matplotlib.org/), and [pandas](http://pandas.pydata.org/).  If you want to get more experience with these, there are great [resources](http://fperez.org/py4science/starter_kit.html) and [tutorials](http://www.rexx.com/~dkuhlman/scipy_course_01.html) covering these libraries in much more [depth](http://scipy-lectures.github.io/) than I will here.  I highly recommend taking a look at these if this analysis interests you even in the least bit."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "To perform some interesting statistical analyses, we first need to \"join\" our CSV files in order to associate businesses \n",
      "with their inspection scores. This data currently resides in data/SFBusinesses/businesses.csv and data/SFBusinesses/inspections.csv\n",
      "'''\n",
      "\n",
      "# import pandas library which provides an R like environment for python.\n",
      "# if you do not have it installed: sudo easy_install pandas.\n",
      "import pandas as pd\n",
      "\n",
      "# store relevant file paths in variables since we may use them frequently\n",
      "root_dir = 'data/SFBusinesses/'\n",
      "businesses = root_dir + 'businesses.csv'\n",
      "inspections = root_dir + 'inspections.csv'\n",
      "\n",
      "\n",
      "# load each file into a Pandas DataFrame, pandas automatically converts the first line into a header for the columns\n",
      "\n",
      "df_business = pd.read_csv(businesses)\n",
      "df_inspection = pd.read_csv(inspections)\n",
      "\n",
      "# inspect the first 10 rows of the DataFrame\n",
      "df_inspection.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>business_id</th>\n",
        "      <th>Score</th>\n",
        "      <th>date</th>\n",
        "      <th>type</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 10</td>\n",
        "      <td>  98</td>\n",
        "      <td> 20121114</td>\n",
        "      <td> routine</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 10</td>\n",
        "      <td>  98</td>\n",
        "      <td> 20120403</td>\n",
        "      <td> routine</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 10</td>\n",
        "      <td> 100</td>\n",
        "      <td> 20110928</td>\n",
        "      <td> routine</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 10</td>\n",
        "      <td>  96</td>\n",
        "      <td> 20110428</td>\n",
        "      <td> routine</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 10</td>\n",
        "      <td> 100</td>\n",
        "      <td> 20101210</td>\n",
        "      <td> routine</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 12</td>\n",
        "      <td> 100</td>\n",
        "      <td> 20121120</td>\n",
        "      <td> routine</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 12</td>\n",
        "      <td>  98</td>\n",
        "      <td> 20120420</td>\n",
        "      <td> routine</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 12</td>\n",
        "      <td> 100</td>\n",
        "      <td> 20111018</td>\n",
        "      <td> routine</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 12</td>\n",
        "      <td> 100</td>\n",
        "      <td> 20110401</td>\n",
        "      <td> routine</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> 17</td>\n",
        "      <td> 100</td>\n",
        "      <td> 20120823</td>\n",
        "      <td> routine</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "   business_id  Score      date     type\n",
        "0           10     98  20121114  routine\n",
        "1           10     98  20120403  routine\n",
        "2           10    100  20110928  routine\n",
        "3           10     96  20110428  routine\n",
        "4           10    100  20101210  routine\n",
        "5           12    100  20121120  routine\n",
        "6           12     98  20120420  routine\n",
        "7           12    100  20111018  routine\n",
        "8           12    100  20110401  routine\n",
        "9           17    100  20120823  routine"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 1.3: Join the businesses.csv and inspections.csv on the business_id column.  \n",
      "* Use pandas DataFrame functions to merge df_businesses and df_inspection.\n",
      "* Inspect the resulting table.\n",
      "\n",
      "#### Extra Credit: \n",
      "* Print out the column names of df_businesses, df_inspection, and the resulting join table.\n",
      "* Display the ['name', 'date', 'Score', 'type'] columns of the result join table for the first 10 records (rows)\n",
      "\n",
      "*Relevant resources:*\n",
      "  \n",
      "* [pandas homepage](http://pandas.pydata.org/)\n",
      "* [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/index.html)\n",
      "* [pandas tutorial](http://www.randalolson.com/2012/08/06/statistical-analysis-made-easy-in-python/)\n",
      "* [pandas: Merge, Join, and Concatenate](http://pandas.pydata.org/pandas-docs/stable/merging.html)\n",
      "* [pandas: Selecting Data](http://pandas.pydata.org/pandas-docs/stable/indexing.html)\n",
      "* [Python for Data Analysis: O'Reilly book](http://my.safaribooksonline.com/book/programming/python/9781449323592)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Now that we have our joined data, we can start exploring it__"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To analyze our businesses we need to perform some basic aggregations and transformations.  Currently each business has multiple rows in the join table (all with the same business_id).  Let us group these records by business and only keep the most recent inspection.\n",
      "\n",
      "### Exercise 1.4: Transform the table to only contain each businesses most recent inspection  \n",
      "* Group the resulting join table by the 'business_id' column.  \n",
      "* Filter the table such that only the most recent score is listed.\n",
      "\n",
      "#### Extra Credit: \n",
      "* Use [pandas function application](http://pandas.pydata.org/pandas-docs/stable/basics.html#function-application) with a [lambda](http://docs.python.org/2/tutorial/controlflow.html#lambda-forms) function.\n",
      "* Instead of the most recent inspection score, return the average of all the inspections.\n",
      "\n",
      "*Relevant resources:*\n",
      "  \n",
      "* [pandas Group By: split-apply-combine](http://pandas.pydata.org/pandas-docs/stable/groupby.html)\n",
      "* [pandas `apply`](http://pandas.pydata.org/pandas-docs/stable/groupby.html#flexible-apply)\n",
      "* [pandas `sort_index`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_index.html#pandas.DataFrame.sort_index)\n",
      "* [pandas `head`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html#pandas.DataFrame.head)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url='http://inundata.org/R_talks/meetup/images/splitapply.png', width=500)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://inundata.org/R_talks/meetup/images/splitapply.png\" width=\"500\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "<IPython.core.display.Image at 0x110ac1410>"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Split-Apply-Combine\n",
      "A visual representation of how group-by, aggregate, and apply semantics work "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__We can bin the restaurants by scores to understand the distribution of inspections better.  Here we create a histogram to understand the distribution of scores better__"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 1.5: Create a histogram of the most recent inspection scores of all the restaurants\n",
      "* Create a [matplotlib](http://matplotlib.org/) figure of a histogram with 100 bins. \n",
      "\n",
      "#### Extra Credit: \n",
      "* Scale the x-axis (inspection scores) to range from 40 to 100, incrementing by 2 (only even values).\n",
      "* Add an appropriate title and axis labels to the graph.\n",
      "\n",
      "*Relevant resources:*\n",
      "  \n",
      "* [pandas: Plotting with matplotlib](http://pandas.pydata.org/pandas-docs/stable/visualization.html)\n",
      "* [Scipy Lectures: matplotlib](http://scipy-lectures.github.io/intro/matplotlib/matplotlib.html)\n",
      "* [matplotlib documentation](http://matplotlib.org/1.2.1/index.html)\n",
      "* [pandas histograms: `hist()`](http://pandas.pydata.org/pandas-docs/stable/visualization.html#histograms)\n",
      "* [pandas: setting major and minor ticks and labels](http://stackoverflow.com/questions/12945971/pandas-timeseries-plot-setting-x-axis-major-and-minor-ticks-and-labels)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is the step where derivative values are often calculated, including __summary statistics__, __transformations__ on the data, and __correlations__.  There also is a bit of traditional __data mining__ involved as most machine learning occurs in the solutions and metrics stages (in our formulation).  We could even go so far as to say that the results of predictive models are simply additional metrics: the __probability__ of defaulting on a loan, the __cluster__ a new product belongs in, or the __score__ of a restaurant that hasn't been inspected yet.\n",
      "    \n",
      "___The purpose of this part of the process is to calculate the information you need to begin evaluating and testing you solutions and hypotheses.___"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 1.6: Compute descriptive statistics of the most recent restaurant inspection scores.\n",
      "__Calculate:__ \n",
      "\n",
      "* total count of inspections\n",
      "* mean\n",
      "* standard deviation\n",
      "* minimum and maximum\n",
      "* quantiles\n",
      "\n",
      "#### Extra Credit: \n",
      "* Do not use pandas `describe()` convenience method.\n",
      "* Add an appropriate title and axis labels to the graph.\n",
      "\n",
      "*Relevant resources:*\n",
      "  \n",
      "* [pandas: Essential Basic Functionality](http://pandas.pydata.org/pandas-docs/stable/basics.html)\n",
      "* [pandas: Descriptive Statistics](http://pandas.pydata.org/pandas-docs/stable/basics.html#descriptive-statistics)\n",
      "* [pandas `describe()`](http://pandas.pydata.org/pandas-docs/stable/basics.html#summarizing-data-describe)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# recall that in the Score Legend, each numeric score corresponds to a more qualitative description\n",
      "!head -n 5 data/SFBusinesses/ScoreLegend.csv | column -t -s ','"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"Minimum_Score\"  \"Maximum_Score\"  \"Description\"\r",
        "\r\n",
        "0                70               \"Poor\"\r",
        "\r\n",
        "71               85               \"Needs Improvement\"\r",
        "\r\n",
        "86               90               \"Adequate\"\r",
        "\r\n",
        "91               100              \"Good\"\r",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 1.7: Quantize the raw numeric inspection scores into the more qualitative scores ('Poor', 'Needs Imporvement', 'Adequate', 'Good') for the inspections.\n",
      "\n",
      "* Discretize the current numeric scores into these 'categorical' descriptions.\n",
      "* Print out the ['name', 'date', 'Score', 'type'] columns of this new table for the first 15 records (rows).\n",
      "\n",
      "#### Extra Credit: \n",
      "* Create a new DataFrame of the original records, but with the 'Score' numeric values replaced by these 'categorical' scores.\n",
      "\n",
      "*Relevant resources:*\n",
      "  \n",
      "* [pandas: Discretization and Quantiling](http://pandas.pydata.org/pandas-docs/stable/basics.html#discretization-and-quantiling)\n",
      "* [pandas `cut()`](http://pandas.pydata.org/pandas-docs/stable/reshaping.html?highlight=cut#tiling)\n",
      "* [pandas `copy()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.copy.html#pandas.DataFrame.copy)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__By quantizing the scores of the restaurant inspections, we can get a better qualitative insight into the ratings.  Let us compare this new distribution of quantized scores to the raw numeric values.__"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 1.8: Create a histogram of these discretized scores ('Poor', 'Needs Imporvement', 'Adequate', 'Good')\n",
      "\n",
      "* Plot the descriptive scores on a histogram with 4 bins -- ['Poor', 'Needs Imporvement', 'Adequate', 'Good']\n",
      "* Print out the ['name', 'date', 'Score', 'type'] columns of this new table for the first 15 records (rows).\n",
      "\n",
      "#### Extra Credit: \n",
      "* Create a figure with 2 [subplots]() to display the raw (numeric) scores histogram next to the quantized (descriptions) histogram.\n",
      "* Decorate both of these subplot each with its own unique title, axis labels, and x-axis ticks/scale. \n",
      "* Arrange data such that 'Poor' is plotted as the left-most bar and 'Good' the right-most bar.\n",
      "* Display the counts of each bin above its associated bar in the histogram.\n",
      "\n",
      "*Relevant resources:*\n",
      "  \n",
      "* [pandas `value_counts()`](http://pandas.pydata.org/pandas-docs/stable/basics.html#value-counts-histogramming)\n",
      "* [pandas bar charts](http://pandas.pydata.org/pandas-docs/stable/visualization.html#bar-plots)\n",
      "* [matplotlib tutorial](http://matplotlib.org/users/pyplot_tutorial.html)\n",
      "* [matplotlib `subplot()`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.subplot)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## ___Time to communicate what you have found___\n",
      "\n",
      "__Once you are satisfied with your analysis and feel that you have accomplished your goals you set out to achieve, it is time to share your work with the world!.__\n",
      "\n",
      "Not only should your final visualization communicate your results, but it should also show your process.  With such wonderful tools as IPython and with [docstrings](http://www.pythonforbeginners.com/basics/python-docstrings/) built into the language, there is no excuse to not document your work and process.  In keeping in line with the [scientific method](https://en.wikipedia.org/wiki/Scientific_method), you want your analyses to be readily reproducible."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 1.9: Create a unique visualization the you feel effectively communicates your analyses.  Some suggestions:\n",
      "\n",
      "* Geographically plot inspection scores on a map of the city.\n",
      "* Create plots of how much each individual inspection compares to the mean/average of SF restuarants.\n",
      "* Overlay common distributions on the histogram (or scatterplot) of restaurant inspection scores for comparison.\n",
      "* Create a heatmap of scores identifying any possible hotspots for 'dirty' restuarants.\n",
      "\n",
      "#### Extra Credit: \n",
      "* Make your map interactive using Javascript.\n",
      "* Use an API ([Yelp](http://www.yelp.com/developers/documentation), [Google Places](https://developers.google.com/places/documentation/), [Foursqaure](https://developer.foursquare.com/)) to augment the health inspection data with reviews, ratings, descriptions, menus, etc.\n",
      "* Share your results by [blogging](https://www.tumblr.com/) about your process and put your code on [Github](https://github.com/) (or a similar service)\n",
      "\n",
      "*Relevant resources:*\n",
      "  \n",
      "* [matplotlib: Basemap](http://matplotlib.org/basemap/users/examples.html)\n",
      "* [folium: Python data. Meet Leaflet maps](https://github.com/wrobstory/folium)\n",
      "* [Polymaps Javascript library](http://polymaps.org/)\n",
      "* [D3.js maps tutorial](http://www.schneidy.com/Tutorials/MapsTutorial.html)\n",
      "* [vincent: Vega with Python](https://github.com/wrobstory/vincent)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}